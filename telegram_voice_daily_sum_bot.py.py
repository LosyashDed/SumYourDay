"""
Voice Telegram Bot
===================
A modular Telegram bot that transcribes incoming voice messages, summarizes them with an
LLM (local or cloud), and stores both the raw transcription and the summary in a database.

Architecture Overview
---------------------
â€¢ ``Database`` â€“ Thin wrapper around SQLite **(switchable to MySQL later)**
â€¢ ``LLMHandler`` â€“ Talks to either a **local** Ollama instance *or* a cloud LLM (e.g. OpenAI)
â€¢ ``SpeechToText`` â€“ Converts OGG âœ WAV (via FFmpeg) and transcribes with **Vosk**
â€¢ ``TelegramBot`` â€“ Handles the Telegram Bot API (using ``pythonâ€‘telegramâ€‘bot`` library)
â€¢ ``Utils`` â€“ Misc. helper utilities (static methods only)

Environment variables are read from a ``.env`` file â€“ **change behaviour by editing the file, not the code**.

Example .env
-------------
```
# â”€â”€â”€ Telegram â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TG_BOT_TOKEN="123456:ABCâ€‘DEFâ€¦â€

# â”€â”€â”€ Database â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DB_PATH="bot.db"              # Path to SQLite file (ignored if you later switch to MySQL)

# â”€â”€â”€ LLM Settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
USE_LOCAL_LLM="True"          # "True" -> Ollama, "False" -> use cloud LLM
OLLAMA_BASE_URL="http://127.0.0.1:11434"  # Where your Ollama server sits
OLLAMA_MODEL="mistral"

OPENAI_API_KEY="skâ€‘â€¦"         # Only required when USE_LOCAL_LLM=False
OPENAI_MODEL="gptâ€‘3.5â€‘turbo"  # or gptâ€‘4o, etc.

# â”€â”€â”€ Speechâ€‘toâ€‘Text â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
VOSK_MODEL_PATH="models/voskâ€‘smallâ€‘ruâ€‘0.22"
FFMPEG_BINARY="ffmpeg"         # Path or command alias

# â”€â”€â”€ Misc â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LOG_FILE="bot.log"             # Where to write debug logs

```

Install dependencies
--------------------
```bash
python -m venv .venv && source .venv/bin/activate
pip install pythonâ€‘telegramâ€‘bot==20.8 pythonâ€‘dotenv requests vosk ffmpegâ€‘python openai
```
(Use ``pip install mysqlâ€‘connectorâ€‘python`` later if/when you migrate the DB.)

Run the bot
-----------
```bash
python voice_telegram_bot.py
```

-------------------------------------------------------------------------------
Below is the **fullyâ€‘commented** implementation. Feel free to slice it into
multiple files once you're comfortable â€“ the class boundaries are already set up
for easy extraction.
-------------------------------------------------------------------------------
"""
from __future__ import annotations

import os
import sqlite3
import logging
import datetime as _dt
import json
import subprocess
import tempfile
from dataclasses import dataclass
from pathlib import Path
from typing import Optional, Dict, Any

import requests
from dotenv import load_dotenv
from vosk import Model, KaldiRecognizer
from telegram import Update, Voice, constants
from telegram.ext import ApplicationBuilder, ContextTypes, MessageHandler, filters

try:
    import openai  # optional â€“ only needed when USE_LOCAL_LLM == False
except ImportError:
    openai = None  # keep linting happy â€“ runtime guard is in LLMHandler

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Utils
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class Utils:
    """Collection of helper static methods."""

    @staticmethod
    def now_utc() -> str:
        """Return current UTC time in ISOâ€‘8601 format (without microseconds)."""
        return _dt.datetime.utcnow().replace(microsecond=0).isoformat()

    @staticmethod
    def ensure_parent(path: Path):
        path.parent.mkdir(parents=True, exist_ok=True)

    @staticmethod
    def as_bool(value: str | bool | None) -> bool:
        if isinstance(value, bool):
            return value
        return str(value).strip().lower() in {"1", "true", "yes", "on"}

    @staticmethod
    def configure_logging(log_path: str):
        fmt = "%(asctime)s | %(levelname)s | %(name)s | %(message)s"
        logging.basicConfig(
            level=logging.INFO,
            format=fmt,
            handlers=[
                logging.FileHandler(log_path, encoding="utfâ€‘8"),
                logging.StreamHandler(),
            ],
        )
        logging.getLogger("httpx").setLevel(logging.WARNING)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Database Layer
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class Database:
    """Lightweight wrapper around SQLite â€“ swappable later for MySQL.

    Only *this* class knows specific SQL dialect details. The rest of the code
    interacts through the typed public interface below. To migrate, rewrite
    these methods and keep signatures intact.
    """

    _CREATE_TABLE_SQL = """
    CREATE TABLE IF NOT EXISTS voice_messages (
        id          INTEGER PRIMARY KEY AUTOINCREMENT,
        telegram_file_id TEXT UNIQUE NOT NULL,
        text        TEXT,
        summarized  TEXT,
        sent_at     TEXT,
        user_id     INTEGER,
        username    TEXT
    );"""

    def __init__(self, path: str):
        Utils.ensure_parent(Path(path))
        self.conn = sqlite3.connect(path, check_same_thread=False)
        self.conn.execute("PRAGMA journal_mode=WAL;")  # better concurrency
        self.conn.execute(self._CREATE_TABLE_SQL)
        self.conn.commit()
        logging.info("Connected to SQLite DB at %s", path)

    def save_message(
        self,
        telegram_file_id: str,
        text: str | None,
        summary: str | None,
        sent_at: str,
        user_id: int,
        username: str | None,
    ) -> None:
        """Insert or update a transcription row."""
        self.conn.execute(
            """
            INSERT INTO voice_messages
                (telegram_file_id, text, summarized, sent_at, user_id, username)
            VALUES (?, ?, ?, ?, ?, ?)
            ON CONFLICT(telegram_file_id) DO UPDATE SET
                text=excluded.text,
                summarized=excluded.summarized;
            """,
            (telegram_file_id, text, summary, sent_at, user_id, username),
        )
        self.conn.commit()
        logging.debug("Saved message %s", telegram_file_id)

    # Example of an accessor you might need later.
    def fetch_last_n(self, n: int = 10):
        cur = self.conn.execute(
            "SELECT * FROM voice_messages ORDER BY id DESC LIMIT ?", (n,)
        )
        return cur.fetchall()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  LLM Handler
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class LLMHandler:
    """Facade that hides whether we call a *local* Ollama model or a *cloud* LLM."""

    def __init__(self, *, use_local: bool, cfg: Dict[str, str]):
        self.use_local = use_local
        self.cfg = cfg
        if not use_local and openai is None:
            raise RuntimeError(
                "OpenAI Python package is not installed but USE_LOCAL_LLM=False." )
        if not use_local:
            openai.api_key = cfg["OPENAI_API_KEY"]

    def summarize(self, text: str) -> str:
        """
        Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ñ€ĞµĞ·ÑĞ¼Ğµ Ñ ÑƒÑ‡Ñ‘Ñ‚Ğ¾Ğ¼ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ğ¸Ğ½Ñ‹.
        Ğ•ÑĞ»Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ¾Ñ‚ĞºĞ»Ğ¾Ğ½ÑĞµÑ‚ÑÑ Ğ¾Ñ‚ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğ° >20 %, Ğ´ĞµĞ»Ğ°ĞµĞ¼
        Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½ÑƒÑ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚ĞºÑƒ â€” Ñ‡Ğ¸ÑĞ»Ğ¾ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚Ğ¾Ğº Ğ±ĞµÑ€Ñ‘Ñ‚ÑÑ Ğ¸Ğ· SUMMARY_MAX_TRIES.
        """
        deviation = int(self.cfg.get("SUMMARY_DEVIATION_PERCENT", 20))

        n = len(text)
        if n < 500:
            min_len, max_len = 150, 250
        else:
            min_len, max_len = max(150, n // 5), n // 3  # 5:1 Ğ¸ 3:1

        # ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ñ€Ğ°Ğ· Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ±Ğ¾Ğ²Ğ°Ñ‚ÑŒ
        tries = int(self.cfg.get("SUMMARY_MAX_TRIES", 2))
        tries = max(1, tries)  # Ñ…Ğ¾Ñ‚Ñ Ğ±Ñ‹ Ğ¾Ğ´Ğ½Ğ°

        def _generate() -> str:
            prompt = (
                "Ğ¡Ğ´ĞµĞ»Ğ°Ğ¹ ĞºÑ€Ğ°Ñ‚ĞºĞ¾Ğµ Ñ€ĞµĞ·ÑĞ¼Ğµ Ğ¾Ğ±ÑŠÑ‘Ğ¼Ğ¾Ğ¼ Ğ¾Ñ‚ "
                f"{min_len} Ğ´Ğ¾ {max_len} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ² (Ğ±ĞµĞ· ĞºĞ°Ğ²Ñ‹Ñ‡ĞµĞº, Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‚ĞµĞºÑÑ‚) "
                "Ğ´Ğ»Ñ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ³Ğ¾ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ğ¾Ğ³Ğ¾ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ:\n\n"
                f"{text}"
            )
            return (
                self._ollama_call(prompt)
                if self.use_local
                else self._openai_call(prompt)
            ).strip()

        for attempt in range(tries):
            summary = _generate()
            length = len(summary)
            if min_len * (1-(deviation/100)) <= length <= max_len * (1+(deviation/100)):
                # Ğ´Ğ¾Ğ¿ÑƒÑĞº Â±20 % â€” ÑƒÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°ĞµÑ‚
                break
            if attempt == tries - 1:
                # Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ÑÑ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚ĞºĞ°, Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ¼ ĞºĞ°Ğº ĞµÑÑ‚ÑŒ
                logging.warning(
                    "Summary length %d Ğ²Ğ½Ğµ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğ° (%dâ€‘%d) Ğ´Ğ°Ğ¶Ğµ Ğ¿Ğ¾ÑĞ»Ğµ %d Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚Ğ¾Ğº",
                    length, min_len, max_len, tries
                )

        return summary

    # â”€â”€â”€ Private helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _ollama_call(self, prompt: str) -> str:
        url = f"{self.cfg['OLLAMA_BASE_URL']}/api/generate"
        payload = {"model": self.cfg["OLLAMA_MODEL"], "prompt": prompt, "stream": False}
        logging.debug("Ollama request: %s", json.dumps(payload)[:200])
        resp = requests.post(url, json=payload, timeout=120)
        resp.raise_for_status()
        summary = resp.json().get("response", "").strip()
        logging.info("Ollama summary len=%d", len(summary))
        return summary

    def _openai_call(self, prompt: str) -> str:
        logging.debug("OpenAI prompt len=%d", len(prompt))
        resp = openai.ChatCompletion.create(
            model=self.cfg["OPENAI_MODEL"],
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
        )
        summary = resp.choices[0].message.content.strip()
        logging.info("OpenAI summary len=%d", len(summary))
        return summary

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Speechâ€‘toâ€‘Text
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class SpeechToText:
    """Handles audio conversion + transcription via Vosk.

    Changing STT backend? Replace *only* this class. Maintain public method
    signatures and the rest of the program will keep working. See the inline
    guide below for hints on swapping models (e.g. Whisper, DeepSpeech â€¦).
    """
    SAMPLE_RATE = 16_000  # ÑƒĞ´Ğ¾Ğ±Ğ½Ğ°Ñ ĞºĞ¾Ğ½ÑÑ‚Ğ°Ğ½Ñ‚Ğ°

    def __init__(self, model_path: str, ffmpeg_cmd: str = "ffmpeg"):
        if not Path(model_path).exists():
            raise FileNotFoundError(f"Vosk model not found: {model_path}")
        self.model = Model(model_path)
        self.ffmpeg_cmd = ffmpeg_cmd
        logging.info("Loaded Vosk model from %s", model_path)

    # ---------------------------------------------------------------------
    #  PUBLIC API
    # ---------------------------------------------------------------------
    def transcribe_ogg_bytes(self, ogg_bytes: bytes) -> str:
        """OGG âœ WAV âœ TEXT (returns transcription)."""
        with tempfile.NamedTemporaryFile(suffix=".ogg", delete=False) as ogg:
            ogg.write(ogg_bytes)
            ogg_path = Path(ogg.name)
        wav_path = ogg_path.with_suffix(".wav")
        self._ogg_to_wav(ogg_path, wav_path)
        text = self._wav_to_text(wav_path)
        # cleanup temp files
        ogg_path.unlink(missing_ok=True)
        wav_path.unlink(missing_ok=True)
        return text

    # ---------------------------------------------------------------------
    #  INTERNAL HELPERS
    # ---------------------------------------------------------------------
    def _ogg_to_wav(self, ogg_path: Path, wav_path: Path) -> None:
        """ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ogg/Opus â†’ WAV 16â€¯kHz mono s16le."""
        cmd = [
            self.ffmpeg_cmd,  # Ğ±ĞµÑ€Ñ‘Ñ‚ÑÑ Ğ¸Ğ· envâ€‘Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹ FFMPEG_BINARY
            "-i", str(ogg_path),
            "-ar", str(self.SAMPLE_RATE),  # Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ° Ğ´Ğ¸ÑĞºÑ€ĞµÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
            "-ac", "1",  # mono
            "-c:a", "pcm_s16le",  # Ğ½ĞµÑĞ¶Ğ°Ñ‚Ñ‹Ğ¹ PCM
            "-y",  # overwrite
            "-loglevel", "quiet",  # Ñ‚Ğ¸ÑˆĞ¸Ğ½Ğ° Ğ² Ğ»Ğ¾Ğ³Ğ¸ FFmpeg
            str(wav_path),
        ]
        subprocess.run(cmd, check=True)

    def _wav_to_text(self, wav_path: Path) -> str:
        """Ğ§Ğ¸Ñ‚Ğ°ĞµÑ‚ WAV Ğ¸ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ Vosk."""
        rec = KaldiRecognizer(self.model, self.SAMPLE_RATE)
        with open(wav_path, "rb") as wf:
            while chunk := wf.read(4000):
                rec.AcceptWaveform(chunk)
        result = json.loads(rec.FinalResult())
        return result.get("text", "").strip()

    # ---------------------------------------------------------------------
    #  HOW TO SWITCH TO ANOTHER STT BACKEND (eg. Whisper)  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ---------------------------------------------------------------------
    # 1. Install the new library (pip installâ€‘U whisperâ€‘cpp â€¦).
    # 2. Delete/replace code inside _wav_to_text() with call into that lib.
    # 3. Make sure transcribe_ogg_bytes() still returns *plain string*.
    # 4. Keep signatures unchanged â‡’ rest of the program stays happy.

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Telegram Bot Wrapper
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class TelegramBot:
    """Encapsulates all Telegramâ€‘specific logic. Runs the event loop."""

    def __init__(
        self,
        token: str,
        db: Database,
        stt: SpeechToText,
        llm: LLMHandler,
    ):
        self.db = db
        self.stt = stt
        self.llm = llm
        self.app = ApplicationBuilder().token(token).build()
        # Register handler for *voice* messages only.
        self.app.add_handler(
            MessageHandler(filters.VOICE & ~filters.COMMAND, self.on_voice)
        )
        logging.info("Telegram bot initialized â€“ waiting for voice messagesâ€¦")

    # ---------------------------------------------------------------------
    async def on_voice(self, update: Update, ctx: ContextTypes.DEFAULT_TYPE):
        assert isinstance(update.effective_message.voice, Voice)
        voice: Voice = update.effective_message.voice
        sent_at = Utils.now_utc()
        user = update.effective_user
        file_id = voice.file_id
        logging.info(
            "Voice received: file_id=%s | from=%s", file_id, user.username or user.id
        )
        tg_file = await ctx.bot.get_file(file_id)
        ogg_bytes = await tg_file.download_as_bytearray()

        # 1ï¸âƒ£ Transcribe
        text = self.stt.transcribe_ogg_bytes(ogg_bytes)
        logging.info("Transcribed %d chars", len(text))

        # 2ï¸âƒ£ Summarize
        summary = self.llm.summarize(text)

        # 3ï¸âƒ£ Persist
        self.db.save_message(
            telegram_file_id=file_id,
            text=text,
            summary=summary,
            sent_at=sent_at,
            user_id=user.id,
            username=user.username,
        )

        # 4ï¸âƒ£ Respond with summary
        await update.message.reply_text(
            f"ğŸ“Œ Ğ ĞµĞ·ÑĞ¼Ğµ: {summary}", parse_mode=constants.ParseMode.HTML
        )

    # ---------------------------------------------------------------------
    def run(self):
        """Kickâ€‘off polling loop (Ctrlâ€‘C to exit)."""
        self.app.run_polling()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Entryâ€‘Point
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    load_dotenv(dotenv_path='.env')

    # Configure logging *first* so other classes can log.
    Utils.configure_logging(os.getenv("LOG_FILE", "bot.log"))

    # Instantiate subâ€‘systems using envâ€‘config.
    db = Database(os.getenv("DB_PATH", "bot.db"))

    stt = SpeechToText(
        model_path=os.getenv("VOSK_MODEL_PATH", "models/voskâ€‘smallâ€‘ruâ€‘0.22"),
        ffmpeg_cmd=os.getenv("FFMPEG_BINARY", "ffmpeg"),
    )

    llm = LLMHandler(
        use_local=Utils.as_bool(os.getenv("USE_LOCAL_LLM", "True")),
        cfg=os.environ,  # pass entire dict; handler reads what it needs
    )

    bot = TelegramBot(
        token=os.environ["TG_BOT_TOKEN"],
        db=db,
        stt=stt,
        llm=llm,
    )

    bot.run()


if __name__ == "__main__":
    try:
        main()
    except Exception as exc:
        logging.exception("Fatal error: %s", exc)
        raise
